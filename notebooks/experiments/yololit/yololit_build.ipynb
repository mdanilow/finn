{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4251a915-791c-48c2-8784-9ae362b5e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vision/danilowi/serious_mot/build_dirs/yololit\n",
      "/home/vision/danilowi/serious_mot/finn\n"
     ]
    }
   ],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "import os\n",
    "from os.path import join\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "    \n",
    "build_dir = os.environ[\"FINN_BUILD_DIR\"]\n",
    "finn_root = os.environ[\"FINN_ROOT\"]\n",
    "MODEL_NAME = 'yololit320'\n",
    "print(build_dir)\n",
    "print(finn_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467d260f-06d0-4af9-9f70-d9efa80d1de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:459: UserWarning: Defining your `__torch_function__` as a plain method is deprecated and will be an error in future, please define it as a classmethod. (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:350.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INIT STRIDE = tensor([ 16.,  32.,  64., 128., 256.])\n",
      "Transferred 452/452 items from best.pt\n",
      "INPUT: torch.Size([1, 3, 320, 320])\n",
      "tensor([[[[0.2353, 0.1373, 0.1333,  ..., 0.8000, 0.9725, 0.4353],\n",
      "          [0.4078, 0.8235, 0.4235,  ..., 0.1569, 0.4902, 0.4235],\n",
      "          [0.3137, 0.6314, 0.2824,  ..., 0.8863, 0.7373, 0.0824],\n",
      "          ...,\n",
      "          [0.8784, 0.1686, 0.9765,  ..., 0.5451, 0.1647, 0.4235],\n",
      "          [0.5647, 0.1725, 0.9255,  ..., 0.6941, 0.0824, 0.4549],\n",
      "          [0.9059, 0.3373, 0.5333,  ..., 0.4745, 0.2549, 0.9098]],\n",
      "\n",
      "         [[0.2078, 0.4196, 0.6471,  ..., 0.3804, 0.1765, 0.8627],\n",
      "          [0.8863, 0.5176, 0.9333,  ..., 0.4980, 0.5373, 0.7490],\n",
      "          [0.1961, 0.1608, 0.1882,  ..., 0.7765, 0.8431, 0.5647],\n",
      "          ...,\n",
      "          [0.5137, 0.4667, 0.8471,  ..., 0.3647, 0.6039, 0.1451],\n",
      "          [0.0353, 0.7804, 0.4627,  ..., 0.6000, 0.2196, 0.7333],\n",
      "          [0.0745, 0.4431, 0.7137,  ..., 0.6039, 0.6784, 0.8941]],\n",
      "\n",
      "         [[0.8706, 0.2000, 0.5333,  ..., 0.0510, 0.4196, 0.2314],\n",
      "          [0.3569, 0.5333, 0.9608,  ..., 0.4471, 0.5490, 0.8078],\n",
      "          [0.5765, 0.0627, 0.5020,  ..., 0.8980, 0.3569, 0.4431],\n",
      "          ...,\n",
      "          [0.1490, 0.2941, 0.0706,  ..., 0.8824, 0.0039, 0.8510],\n",
      "          [0.5882, 0.7216, 0.4157,  ..., 0.8941, 0.1216, 0.6078],\n",
      "          [0.1725, 0.4314, 0.0745,  ..., 0.0392, 0.7647, 0.7608]]]])\n",
      "OUTPUT: [torch.Size([1, 255, 20, 20]), torch.Size([1, 255, 10, 10]), torch.Size([1, 255, 5, 5]), torch.Size([1, 255, 3, 3]), torch.Size([1, 255, 2, 2])]\n",
      "[tensor([[[[-1.8395e-01,  5.8247e-02, -1.2654e-01,  ..., -4.5003e-01,\n",
      "            1.6761e-01,  3.9053e-01],\n",
      "          [ 1.4205e-01,  2.1831e-01,  3.6039e-02,  ...,  1.8060e-01,\n",
      "           -6.1177e-01,  4.0227e-01],\n",
      "          [ 2.6692e-01, -1.7012e-01,  9.6403e-03,  ..., -2.0741e-01,\n",
      "            1.0266e-01,  4.4375e-01],\n",
      "          ...,\n",
      "          [-3.4904e-01, -1.5504e-01,  2.8201e-01,  ..., -1.6928e-01,\n",
      "           -3.7290e-02,  1.8312e-01],\n",
      "          [-3.1804e-01,  3.5743e-01, -1.8227e-01,  ..., -4.3576e-02,\n",
      "            4.3956e-01,  4.8188e-01],\n",
      "          [ 5.4895e-02,  1.3535e-01, -1.5545e-01,  ..., -2.5434e-01,\n",
      "            1.6887e-01,  2.5351e-01]],\n",
      "\n",
      "         [[-2.7939e-01, -6.1020e-01, -5.2768e-01,  ...,  1.0153e-02,\n",
      "           -2.3330e-01, -2.5441e-04],\n",
      "          [-2.9538e-01, -2.6644e-02, -2.3256e-01,  ..., -6.1169e-01,\n",
      "           -9.1461e-01,  9.1925e-02],\n",
      "          [ 4.2490e-02,  9.6757e-02, -3.9713e-03,  ...,  1.2649e-01,\n",
      "            3.2454e-02,  3.2083e-02],\n",
      "          ...,\n",
      "          [ 6.8077e-03,  1.8819e-01, -7.4964e-02,  ..., -6.9389e-02,\n",
      "           -3.1105e-02,  1.4062e-01],\n",
      "          [ 3.3650e-01,  1.3318e-01, -7.2734e-02,  ..., -7.6079e-02,\n",
      "           -9.0681e-01, -2.1286e-01],\n",
      "          [ 2.8669e-01,  7.1451e-01,  5.2866e-01,  ...,  3.1828e-01,\n",
      "            7.8141e-01,  1.5511e-01]],\n",
      "\n",
      "         [[ 1.4878e+00,  1.0357e+00,  1.2272e+00,  ...,  8.5551e-01,\n",
      "            1.0643e+00,  1.0487e+00],\n",
      "          [ 1.4939e+00,  1.3391e+00,  1.4571e+00,  ...,  1.1140e+00,\n",
      "            7.6864e-01,  9.9900e-01],\n",
      "          [ 1.0318e+00,  1.3486e+00,  1.3007e+00,  ...,  1.3387e+00,\n",
      "            1.2868e+00,  6.3466e-01],\n",
      "          ...,\n",
      "          [ 3.9695e-01,  1.4411e+00,  1.1455e+00,  ...,  1.3491e+00,\n",
      "            1.0280e+00,  9.3546e-01],\n",
      "          [ 4.9593e-01,  1.3089e+00,  1.5691e+00,  ...,  1.2268e+00,\n",
      "            7.8377e-01,  9.3417e-01],\n",
      "          [ 9.0780e-01,  1.3945e+00,  1.4502e+00,  ...,  1.1373e+00,\n",
      "            1.2730e+00,  4.6394e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7193e+00, -5.3864e+00, -4.5304e+00,  ..., -4.2637e+00,\n",
      "           -4.7636e+00, -5.2093e+00],\n",
      "          [-4.2845e+00, -5.0447e+00, -4.2149e+00,  ..., -3.4981e+00,\n",
      "           -4.3297e+00, -4.0721e+00],\n",
      "          [-4.8450e+00, -4.4499e+00, -4.5503e+00,  ..., -4.1218e+00,\n",
      "           -3.7177e+00, -3.6255e+00],\n",
      "          ...,\n",
      "          [-4.4653e+00, -4.8278e+00, -4.1806e+00,  ..., -3.8624e+00,\n",
      "           -4.0802e+00, -4.2773e+00],\n",
      "          [-5.5148e+00, -4.3324e+00, -4.7781e+00,  ..., -4.8314e+00,\n",
      "           -5.1342e+00, -4.6551e+00],\n",
      "          [-4.4309e+00, -4.9715e+00, -4.7057e+00,  ..., -4.3541e+00,\n",
      "           -4.2257e+00, -4.7338e+00]],\n",
      "\n",
      "         [[-7.7862e+00, -7.3550e+00, -7.1903e+00,  ..., -7.2476e+00,\n",
      "           -7.4326e+00, -7.7014e+00],\n",
      "          [-7.6562e+00, -7.5835e+00, -7.4954e+00,  ..., -6.8869e+00,\n",
      "           -7.0471e+00, -7.1033e+00],\n",
      "          [-7.7399e+00, -7.4937e+00, -7.4023e+00,  ..., -7.5207e+00,\n",
      "           -7.0895e+00, -7.3753e+00],\n",
      "          ...,\n",
      "          [-7.4166e+00, -7.7261e+00, -7.5929e+00,  ..., -7.1920e+00,\n",
      "           -7.2250e+00, -7.3373e+00],\n",
      "          [-8.0808e+00, -7.9541e+00, -7.7460e+00,  ..., -7.4398e+00,\n",
      "           -7.5312e+00, -7.6645e+00],\n",
      "          [-7.6859e+00, -7.5604e+00, -7.2850e+00,  ..., -7.9514e+00,\n",
      "           -7.8566e+00, -7.9216e+00]],\n",
      "\n",
      "         [[-6.5128e+00, -5.6201e+00, -5.3096e+00,  ..., -5.0834e+00,\n",
      "           -5.2641e+00, -6.0315e+00],\n",
      "          [-6.2666e+00, -5.5602e+00, -5.5602e+00,  ..., -5.2242e+00,\n",
      "           -4.8826e+00, -5.4815e+00],\n",
      "          [-5.9705e+00, -6.1435e+00, -5.3961e+00,  ..., -5.3584e+00,\n",
      "           -4.8915e+00, -5.6911e+00],\n",
      "          ...,\n",
      "          [-4.9702e+00, -5.9661e+00, -5.6600e+00,  ..., -5.4338e+00,\n",
      "           -4.8715e+00, -5.2430e+00],\n",
      "          [-5.5835e+00, -5.4050e+00, -5.8630e+00,  ..., -5.5092e+00,\n",
      "           -4.9691e+00, -5.5879e+00],\n",
      "          [-5.8641e+00, -5.9240e+00, -5.3872e+00,  ..., -6.3620e+00,\n",
      "           -6.0748e+00, -5.8707e+00]]]], grad_fn=<ConvolutionBackward0>), tensor([[[[-0.1391, -0.2198, -0.1056,  ..., -0.0767,  0.1870, -0.3345],\n",
      "          [-0.2640, -0.4034, -0.0698,  ..., -0.1951, -0.0870,  0.1870],\n",
      "          [-0.3520, -0.0608, -0.0921,  ..., -0.1924,  0.0570, -0.0560],\n",
      "          ...,\n",
      "          [-0.3453, -0.1189, -0.0307,  ..., -0.0638, -0.2014, -0.0770],\n",
      "          [-0.2083, -0.2697, -0.6085,  ..., -0.4766, -0.0999, -0.2267],\n",
      "          [-0.2559,  0.0515, -0.7018,  ..., -0.4784, -0.2261,  0.1039]],\n",
      "\n",
      "         [[-0.0425,  0.3501,  0.1177,  ...,  0.2876,  0.0995, -0.1538],\n",
      "          [-0.5362, -0.6760, -0.8443,  ..., -1.0877, -0.5770, -0.3345],\n",
      "          [-0.5878, -0.1276,  0.1165,  ...,  0.0231,  0.2783, -0.5439],\n",
      "          ...,\n",
      "          [-0.0295,  0.0089, -0.0592,  ..., -0.1381, -0.4551,  0.0404],\n",
      "          [ 0.6656,  0.4688, -0.1702,  ...,  0.5459,  0.3767,  0.4129],\n",
      "          [-0.7227, -0.2748, -0.0487,  ...,  0.0098, -0.2064, -0.6076]],\n",
      "\n",
      "         [[ 0.6394,  1.1893,  1.2172,  ...,  1.3739,  1.8199,  1.2507],\n",
      "          [ 0.4050,  1.0699,  1.3387,  ...,  1.0811,  1.1180,  0.4501],\n",
      "          [ 0.2732,  0.9579,  1.1339,  ...,  1.1747,  1.0948,  1.0098],\n",
      "          ...,\n",
      "          [ 0.2414,  1.1416,  0.9819,  ...,  1.1154,  1.0017,  0.9927],\n",
      "          [ 0.4994,  1.4631,  1.0725,  ...,  0.8085,  1.0304,  1.2322],\n",
      "          [ 0.4484,  1.9315,  1.1275,  ...,  0.6402,  1.0970,  0.7428]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1319, -4.4180, -4.7378,  ..., -4.3462, -4.7983, -4.9876],\n",
      "          [-5.0740, -4.6012, -4.9841,  ..., -4.7654, -4.7335, -5.0083],\n",
      "          [-5.2529, -4.9349, -5.0083,  ..., -5.1587, -4.9521, -5.2460],\n",
      "          ...,\n",
      "          [-5.0222, -4.0878, -4.4854,  ..., -4.9547, -5.1241, -4.9254],\n",
      "          [-5.2884, -4.7006, -4.1518,  ..., -4.7680, -4.8700, -4.9271],\n",
      "          [-5.1190, -5.0844, -4.9599,  ..., -5.2633, -5.1086, -5.0792]],\n",
      "\n",
      "         [[-7.1307, -7.3438, -7.2076,  ..., -7.1320, -7.4271, -7.5405],\n",
      "          [-7.4979, -7.4971, -7.4188,  ..., -7.4781, -7.6512, -7.5738],\n",
      "          [-7.1030, -7.5790, -7.3732,  ..., -7.5359, -7.3470, -7.6664],\n",
      "          ...,\n",
      "          [-7.6108, -7.4690, -7.2800,  ..., -7.2199, -7.5171, -7.6224],\n",
      "          [-7.9014, -7.6501, -7.3675,  ..., -7.5132, -7.6508, -7.7810],\n",
      "          [-7.7437, -7.5079, -7.4425,  ..., -7.6622, -7.5598, -7.7668]],\n",
      "\n",
      "         [[-5.4958, -6.1867, -5.3331,  ..., -5.4910, -6.4159, -6.5801],\n",
      "          [-5.8047, -5.2736, -5.6376,  ..., -6.0097, -6.5970, -6.3586],\n",
      "          [-4.5596, -5.4157, -5.6064,  ..., -6.2605, -6.1669, -6.5308],\n",
      "          ...,\n",
      "          [-5.9233, -5.5616, -5.3658,  ..., -5.8576, -5.8921, -6.1246],\n",
      "          [-6.2572, -6.0185, -4.9037,  ..., -5.7423, -6.4647, -6.7523],\n",
      "          [-6.8107, -6.1232, -5.6141,  ..., -6.7927, -6.6561, -7.0098]]]],\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[-0.0318, -0.7255, -0.5714,  0.3884, -0.5212],\n",
      "          [-0.1476, -0.8170, -0.7187, -0.1328, -0.2868],\n",
      "          [-0.0949, -0.3195, -0.7249,  0.3172, -0.3035],\n",
      "          [ 0.0431, -1.1327, -0.2234, -0.0697, -0.3164],\n",
      "          [ 0.2344, -1.5183, -0.6599, -0.0675, -0.1873]],\n",
      "\n",
      "         [[ 0.0369,  0.1913, -0.0973, -0.0152, -0.1781],\n",
      "          [-0.8874, -1.2559, -0.1400, -0.8378, -0.3440],\n",
      "          [-0.0966, -0.1478, -0.0542, -0.0751,  0.0556],\n",
      "          [ 0.6848,  0.6337,  0.1158, -0.0346,  0.0675],\n",
      "          [-0.5664, -0.2576,  0.1720, -0.3942, -0.3365]],\n",
      "\n",
      "         [[ 0.3897,  1.8894,  0.4366,  1.4963,  1.1301],\n",
      "          [ 0.2328,  1.4029,  0.5794,  1.7750,  0.8840],\n",
      "          [ 0.3926,  0.8880,  0.3975,  1.2374,  0.9022],\n",
      "          [ 0.5225,  1.2079,  1.0208,  2.0520,  0.8894],\n",
      "          [ 0.8134,  1.6720,  0.6774,  0.6855,  0.7601]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.0415, -6.2436, -6.3787, -5.4019, -5.7583],\n",
      "          [-6.1909, -5.8606, -6.1605, -5.7688, -5.9876],\n",
      "          [-6.2188, -6.0992, -6.4202, -5.9312, -6.1227],\n",
      "          [-5.3592, -5.1776, -5.0673, -4.8999, -5.2297],\n",
      "          [-5.8544, -5.0747, -6.2324, -6.0490, -6.0366]],\n",
      "\n",
      "         [[-8.0863, -8.2109, -8.2011, -8.2612, -8.2228],\n",
      "          [-8.1510, -8.3878, -8.3087, -8.3579, -8.1946],\n",
      "          [-8.0701, -8.1906, -8.1656, -8.2175, -8.1325],\n",
      "          [-8.2103, -8.3688, -8.2774, -8.3396, -8.2173],\n",
      "          [-8.1570, -8.4030, -8.2487, -8.1979, -8.1588]],\n",
      "\n",
      "         [[-7.0973, -6.4410, -7.0828, -6.8655, -6.7799],\n",
      "          [-6.8876, -6.9602, -7.4505, -7.1192, -6.7753],\n",
      "          [-7.0424, -6.8277, -7.0607, -6.5572, -6.2174],\n",
      "          [-6.8099, -6.9227, -6.5199, -6.3169, -5.6804],\n",
      "          [-6.8775, -6.3739, -7.1622, -7.0061, -6.9895]]]],\n",
      "       grad_fn=<ConvolutionBackward0>), tensor([[[[ 7.4496,  5.1639,  4.8662],\n",
      "          [ 6.4908,  5.0756,  4.5593],\n",
      "          [ 7.1522,  4.7241,  3.5918]],\n",
      "\n",
      "         [[ 6.1188,  4.1753,  3.8780],\n",
      "          [ 5.4562,  3.9809,  3.6078],\n",
      "          [-3.2125,  2.5721,  1.3620]],\n",
      "\n",
      "         [[ 8.5949,  8.0733,  8.0527],\n",
      "          [ 8.2258,  7.9594,  7.9088],\n",
      "          [ 8.4968,  7.8609,  7.8803]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6511, -6.2142, -4.6029],\n",
      "          [-5.2453, -5.1112, -4.1466],\n",
      "          [-5.1112, -4.3391, -3.8395]],\n",
      "\n",
      "         [[-9.7578, -9.7384, -9.6895],\n",
      "          [-9.8524, -9.9181, -9.7580],\n",
      "          [-9.6912, -9.7554, -9.6122]],\n",
      "\n",
      "         [[-7.7712, -7.7688, -7.5823],\n",
      "          [-8.1396, -8.3249, -7.6801],\n",
      "          [-7.7063, -8.0700, -7.5115]]]], grad_fn=<ConvolutionBackward0>), tensor([[[[-0.3215, -3.2670],\n",
      "          [-0.6753, -1.4436]],\n",
      "\n",
      "         [[ 5.4169,  5.4467],\n",
      "          [ 4.7357,  4.8463]],\n",
      "\n",
      "         [[ 4.3921,  4.5603],\n",
      "          [ 3.7175,  3.8643]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.8340, -5.8085],\n",
      "          [-5.7752, -5.7773]],\n",
      "\n",
      "         [[-5.9631, -6.0811],\n",
      "          [-5.9845, -5.9933]],\n",
      "\n",
      "         [[-6.0047, -6.0691],\n",
      "          [-5.9814, -5.9832]]]], grad_fn=<ConvolutionBackward0>)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vision/danilowi/serious_mot/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    RemoveStaticGraphInputs,\n",
    ")\n",
    "import onnx\n",
    "from brevitas.export import export_qonnx\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.util.pytorch import ToTensor\n",
    "\n",
    "from models.yolo import get_model\n",
    "from models.finn_models import QuantDetect\n",
    "\n",
    "net, _ = get_model('yololit.yaml', 'best.pt', backbone_only=False)\n",
    "model = net.eval()\n",
    "for m in model.modules():\n",
    "    if isinstance(m, QuantDetect):\n",
    "        m.finn_export = True\n",
    "\n",
    "# test input\n",
    "test_input_np = (np.random.rand(1, 3, 320, 320) * 255).astype(np.uint8)\n",
    "np.save(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test_input_320x320.npy\"), test_input_np)\n",
    "# test_input_np = np.load(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test_input_320x320.npy\"))\n",
    "test_input = torch.from_numpy(test_input_np).float() / 255.0\n",
    "\n",
    "print('INPUT:', test_input.shape)\n",
    "print(test_input)\n",
    "output_golden = model(test_input)\n",
    "print('OUTPUT:', [x.shape for x in output_golden] if isinstance(output_golden, list) else output_golden.shape)\n",
    "print(output_golden)\n",
    "for i, out in enumerate(output_golden):\n",
    "    np.save(join(finn_root, \"notebooks\", \"experiments\", \"yolov8\", MODEL_NAME + \"_output_golden_{}.npy\".format(i)), out.detach())\n",
    "\n",
    "# onnx export\n",
    "model_file = join(finn_root, \"notebooks\", \"experiments\", \"yololit\", MODEL_NAME + \".onnx\")\n",
    "onnx_model = export_qonnx(model, test_input, model_file)\n",
    "model = ModelWrapper(model_file)\n",
    "model = cleanup_model(model)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# add preprocessing\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "chkpt_preproc_name = join(build_dir, \"preproc.onnx\")\n",
    "export_qonnx(ToTensor(), torch.randn(ishape), chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = cleanup_model(pre_model)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "# final cleanup\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8010b6-fda1-4fc6-bc7a-7f20db4545a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/finn/notebooks/experiments/yololit/yololit320.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6783c9b2e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2ea0b1a-4e18-4f70-95ee-a3e770b7b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.general import (\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    ApplyConfig,\n",
    ")\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.streamline import Streamline\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "model = ModelWrapper(model_file)\n",
    "# model = ModelWrapper(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test2.onnx\"))\n",
    "model = model.transform(Streamline())\n",
    "model.save(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test.onnx\"))\n",
    "model = model.transform(reorder.MoveLinearPastFork())\n",
    "model = model.transform(reorder.MoveMulPastJoinAdd())\n",
    "model = model.transform(reorder.MoveLinearPastFork())\n",
    "model = model.transform(reorder.MoveMulPastJoinAdd())\n",
    "\n",
    "model = model.transform(Streamline())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model.save(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test3.onnx\"))\n",
    "\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test4.onnx\"))\n",
    "\n",
    "\n",
    "# def clean(model):\n",
    "#     model = model.transform(GiveUniqueNodeNames())\n",
    "#     model = model.transform(GiveReadableTensorNames())\n",
    "#     model = model.transform(InferDataTypes())\n",
    "#     model = model.transform(InferDataLayouts())\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88aa41ef-1374-4c20-acc4-4d0899972fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/finn/notebooks/experiments/yololit/yololit320.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f66a41ccdc0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dcad20a-6413-4e21-8b8b-ddba44e15037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/finn/notebooks/experiments/yololit/test3.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f66a4381330>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test3.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d11533a2-477f-48ac-9aef-cbad7e8094c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/finn/notebooks/experiments/yololit/test4.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f66a41cefe0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test4.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78e6cdc6-c601-4630-a624-e5e45647895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "\n",
    "\n",
    "model = ModelWrapper(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"test4.onnx\"))\n",
    "\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model = model.transform(to_hw.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(to_hw.InferVectorVectorActivation())\n",
    "model = model.transform(to_hw.InferPool())\n",
    "model = model.transform(to_hw.InferConvInpGen())\n",
    "model = model.transform(to_hw.InferAddStreamsLayer())\n",
    "model = model.transform(to_hw.InferConcatLayer())\n",
    "model = model.transform(to_hw.InferSplitLayer())\n",
    "model = model.transform(to_hw.InferUpsample())\n",
    "model = model.transform(to_hw.InferDuplicateStreamsLayer()) \n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "\n",
    "model.save(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"hw.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2541e8bc-4469-423a-9b1f-95c6831a6bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/finn/notebooks/experiments/yololit/hw.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f66a450bf40>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(join(finn_root, \"notebooks\", \"experiments\", \"yololit\", \"hw.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40bd5f4-338f-40e9-802f-c18082fa70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:2222\n",
      "Serving '/home/vision/danilowi/serious_mot/build_dirs/yololit/yololit_fifosizing/intermediate_models/step_hw_ipgen.onnx' at http://0.0.0.0:2222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:2222/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd8e03587c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron(join(build_dir, \"yololit_fifosizing\", \"intermediate_models\", \"step_hw_ipgen.onnx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9afd24f-f6c2-46d0-b8d1-aec7f4ef6905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supported_op_partitions\t\t      step_apply_folding_config.onnx\n",
      "dataflow_parent.onnx\t\t      step_minimize_bit_width.onnx\n",
      "step_create_dataflow_partition.onnx   step_generate_estimate_reports.onnx\n",
      "step_specialize_layers.onnx\t      step_hw_codegen.onnx\n",
      "step_target_fps_parallelization.onnx  step_hw_ipgen.onnx\n"
     ]
    }
   ],
   "source": [
    "intermediate_models = join(build_dir, \"yololit_fifosizing\", \"intermediate_models\")\n",
    "!ls -tr {intermediate_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1050358-30ff-4491-8fb8-9435a34838a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
